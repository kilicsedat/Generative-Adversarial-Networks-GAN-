{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, depths=[1024, 512, 256, 128], s_size=4):\n",
    "        #Change for greyscale changed from 3 to 1\n",
    "        self.depths = depths + [1]\n",
    "        self.s_size = s_size\n",
    "        self.reuse = False\n",
    "        print('self.depths', depths)\n",
    "\n",
    "    def __call__(self, inputs, training=False):\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        print('Inside Generator Inputs', inputs)\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            with tf.variable_scope('reshape'):\n",
    "                outputs = tf.layers.dense(inputs, self.depths[0] * self.s_size * self.s_size)\n",
    "                outputs = tf.reshape(outputs, [-1, self.s_size, self.s_size, self.depths[0]])\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            # deconvolution (transpose of convolution) x 4\n",
    "            with tf.variable_scope('deconv1'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[1], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv2'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[2], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv3'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[3], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv4'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[4], [5, 5], strides=(2, 2), padding='SAME')\n",
    "            # output images\n",
    "            with tf.variable_scope('tanh'):\n",
    "                outputs = tf.tanh(outputs, name='outputs')\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, depths=[64, 128, 256, 512]):\n",
    "        #Change for greyscale made 3 to 1\n",
    "        self.depths = [1] + depths\n",
    "        self.reuse = False\n",
    "\n",
    "    def __call__(self, inputs, training=False):\n",
    "        def leaky_relu(x, leak=0.2, name=''):\n",
    "            return tf.maximum(x, x * leak, name=name)\n",
    "        outputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('d', reuse=self.reuse):\n",
    "            # convolution x 4\n",
    "            with tf.variable_scope('conv1'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[1], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv2'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[2], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv3'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[3], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv4'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[4], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('classify'):\n",
    "                batch_size = outputs.get_shape()[0].value\n",
    "                reshape = tf.reshape(outputs, [batch_size, -1])\n",
    "                outputs = tf.layers.dense(reshape, 2, name='outputs')\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self,\n",
    "                 batch_size=16, s_size=4, z_dim=100,\n",
    "                 g_depths=[1024, 512, 256, 128],\n",
    "                 d_depths=[64, 128, 256, 512]):\n",
    "        self.batch_size = batch_size\n",
    "        self.s_size = s_size\n",
    "        self.z_dim = z_dim\n",
    "        self.g = Generator(depths=g_depths, s_size=self.s_size)\n",
    "        self.d = Discriminator(depths=d_depths)\n",
    "        self.z = tf.random_uniform([self.batch_size, self.z_dim], minval=-1.0, maxval=1.0)\n",
    "\n",
    "    def loss(self, traindata):\n",
    "        \"\"\"build models, calculate losses.\n",
    "        Args:\n",
    "            traindata: 4-D Tensor of shape `[batch, height, width, channels]`.\n",
    "        Returns:\n",
    "            dict of each models' losses.\n",
    "        \"\"\"\n",
    "        print('self.z is', self.z)\n",
    "        generated = self.g(self.z, training=True)\n",
    "        g_outputs = self.d(generated, training=True)\n",
    "        t_outputs = self.d(traindata, training=True)\n",
    "        # add each losses to collection\n",
    "        tf.add_to_collection(\n",
    "            'g_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.ones([self.batch_size], dtype=tf.int64),\n",
    "                    logits=g_outputs)))\n",
    "        tf.add_to_collection(\n",
    "            'd_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.ones([self.batch_size], dtype=tf.int64),\n",
    "                    logits=t_outputs)))\n",
    "        tf.add_to_collection(\n",
    "            'd_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.zeros([self.batch_size], dtype=tf.int64),\n",
    "                    logits=g_outputs)))\n",
    "        return {\n",
    "            self.g: tf.add_n(tf.get_collection('g_losses'), name='total_g_loss'),\n",
    "            self.d: tf.add_n(tf.get_collection('d_losses'), name='total_d_loss'),\n",
    "        }\n",
    "\n",
    "    def train(self, losses, learning_rate=0.00002, beta1=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            losses dict.\n",
    "        Returns:\n",
    "            train op.\n",
    "        \"\"\"\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "        g_opt_op = g_opt.minimize(losses[self.g], var_list=self.g.variables)\n",
    "        d_opt_op = d_opt.minimize(losses[self.d], var_list=self.d.variables)\n",
    "        with tf.control_dependencies([g_opt_op, d_opt_op]):\n",
    "            return tf.no_op(name='train')\n",
    "\n",
    "    def sample_images(self, row=8, col=8, inputs=None):\n",
    "        if inputs is None:\n",
    "            inputs = self.z\n",
    "        images = self.g(inputs, training=True)\n",
    "        images = tf.image.convert_image_dtype(tf.div(tf.add(images, 1.0), 2.0), tf.uint8)\n",
    "        images = [image for image in tf.split(images, self.batch_size, axis=0)]\n",
    "        rows = []\n",
    "        for i in range(row):\n",
    "            rows.append(tf.concat(images[col * i + 0:col * i + col], 0))\n",
    "        image = tf.concat(rows, 1)\n",
    "        return tf.image.encode_png(tf.squeeze(image, [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.depths [1024, 512, 256, 128]\n",
      "batch_size: 16\n",
      "s_size 10\n",
      "path is: data\n",
      "['data\\\\gun_train_00000-of-00002.tfrecord', 'data\\\\gun_train_00001-of-00002.tfrecord', 'data\\\\gun_validation_00000-of-00002.tfrecord', 'data\\\\gun_validation_00001-of-00002.tfrecord']\n",
      "WARNING:tensorflow:From <ipython-input-5-8d0df8fc5c14>:30: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "<tensorflow.python.ops.data_flow_ops.FIFOQueue object at 0x0000019B47E24CF8>\n",
      "WARNING:tensorflow:From <ipython-input-5-8d0df8fc5c14>:33: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-5-8d0df8fc5c14>:47: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "Images are: Tensor(\"shuffle_batch:0\", shape=(16, 164, 164, 1), dtype=float32)\n",
      "Train data Tensor(\"Sub:0\", shape=(16, 160, 160, 1), dtype=float32)\n",
      "self.z is Tensor(\"random_uniform:0\", shape=(16, 100), dtype=float32)\n",
      "Inside Generator Inputs Tensor(\"random_uniform:0\", shape=(16, 100), dtype=float32)\n",
      "INFO:tensorflow:Summary name g loss is illegal; using g_loss instead.\n",
      "INFO:tensorflow:Summary name d loss is illegal; using d_loss instead.\n",
      "G checkpoint path:  logdir/gckpt/\n",
      "D Checkpoint Path: logdir/dckpt/\n",
      "INFO:tensorflow:Restoring parameters from logdir/gckpt/g.ckpt-90000\n",
      "Model restored from logdir/gckpt/g.ckpt-90000\n",
      "INFO:tensorflow:Restoring parameters from logdir/dckpt/d.ckpt-90000\n",
      "Model restored from logdir/dckpt/d.ckpt-90000\n",
      "Inside Generator Inputs Tensor(\"Const_3:0\", shape=(16, 100), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-8d0df8fc5c14>:118: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-03-14 21:05:37.661425: step 90000, loss = (G: 10.80769157, D: 0.00002030) (12.237 sec/batch)\n",
      "Save mode for G in checkpoint_path:  logdir/gckpt/\n",
      "Save mode for D in checkpoint_path:  logdir/dckpt/\n",
      "2019-03-14 21:05:51.434020: step 90001, loss = (G: 14.15175819, D: 0.00000074) (7.997 sec/batch)\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node shuffle_batch/random_shuffle_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, random_flip_left_right/Merge)]]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n",
      "Exception in thread QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node shuffle_batch/random_shuffle_queue_enqueue}} = QueueEnqueueV2[Tcomponents=[DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, random_flip_left_right/Merge)]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer/input_producer_EnqueueMany}} = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer, input_producer/RandomShuffle)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"C:\\Users\\sedkilic\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer/input_producer_EnqueueMany}} = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_producer, input_producer/RandomShuffle)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('logdir', 'logdir/',\n",
    "                           \"\"\"logs and checkpoint data are saved in this directory.\"\"\")\n",
    "tf.app.flags.DEFINE_string('images_dir', 'images/',\n",
    "                           \"\"\"Images generated by the generator are saved in this directory\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', 'data',\n",
    "                           \"\"\"Path to read the data from. The data has to be in .tfrecord format.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples_per_epoch_for_train', 5000,\n",
    "                            \"\"\"Number of examples per epoch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 90001,\n",
    "                            \"\"\"Maximum number of steps to run the training.\"\"\")\n",
    "\n",
    "#Size of input images: INPUT_IMAGE_SIZE X INPUT_IMAGE_SIZE\n",
    "INPUT_IMAGE_SIZE = 164\n",
    "#Defining cropped image size\n",
    "#Cropping the input images to the size: crop_image_size X crop_image_size\n",
    "CROP_IMAGE_SIZE = 164\n",
    "\n",
    "#Function used to read the input greyscale images from the .tfrecord files present in the data_dir.\n",
    "def inputs(batch_size, s_size):\n",
    "    print('batch_size:', batch_size)\n",
    "    print('s_size', s_size)\n",
    "    print('path is:', os.path.join(FLAGS.data_dir))\n",
    "    #Picking all the files ending in .tfrecord\n",
    "    files = [os.path.join(FLAGS.data_dir, f) for f in os.listdir(FLAGS.data_dir) if f.endswith('.tfrecord')]\n",
    "    print(files)\n",
    "    #Using string_input_producer() to output the files into a queue which can then be used for an input pipeline. \n",
    "    fqueue = tf.train.string_input_producer(files)\n",
    "    print(fqueue)\n",
    "    #Using the TFRecordReader to output records from a .tfrecord file.\n",
    "    reader = tf.TFRecordReader()\n",
    "    #Using the read method of the TFRecordReader() class to read the next record from the queue. \n",
    "    _, value = reader.read(fqueue)\n",
    "    #From the value extracting a particular feature with key 'image/encoded'.\n",
    "    features = tf.parse_single_example(value, features={'image/encoded': tf.FixedLenFeature([], tf.string)})\n",
    "    #change for greyscale changed from 3 to 1 chanels value. \n",
    "    #Decoding the feature as an .png image and casting it as an image. Since we want to retrieve a greyscale image the number of channels=1\n",
    "    image = tf.cast(tf.image.decode_png(features['image/encoded'], channels=1), tf.float32)\n",
    "    # Resizing the image to the size of the cropped image\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, CROP_IMAGE_SIZE, CROP_IMAGE_SIZE)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    min_queue_examples = FLAGS.num_examples_per_epoch_for_train\n",
    "    # shuffle the images into batchs of batch sizes.\n",
    "    images = tf.train.shuffle_batch( [image], batch_size=batch_size, capacity=min_queue_examples + 3 * batch_size, min_after_dequeue=min_queue_examples)\n",
    "    print('Images are:', images)\n",
    "    tf.summary.image('images', images)\n",
    "    return tf.subtract(tf.div(tf.image.resize_images(images, [s_size * 2 ** 4, s_size * 2 ** 4]), 127.5), 1.0)\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    #Creating an object of the DCGAN\n",
    "    dcgan = DCGAN(s_size=10)\n",
    "    #Call to function to read data in .tfrecord format\n",
    "    traindata = inputs(dcgan.batch_size, dcgan.s_size)\n",
    "    print('Train data', traindata)\n",
    "    # Calculating the losses\n",
    "    losses = dcgan.loss(traindata)\n",
    "    # Extracting the Generator and Discrimintor loss\n",
    "    tf.summary.scalar('g loss', losses[dcgan.g])\n",
    "    tf.summary.scalar('d loss', losses[dcgan.d])\n",
    "    #Minimize the Generator and the Discrimintor losses\n",
    "    train_op = dcgan.train(losses)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    #Creating objects to save the generator and discriminator states\n",
    "    g_saver = tf.train.Saver(dcgan.g.variables)\n",
    "    d_saver = tf.train.Saver(dcgan.d.variables)\n",
    "    #Defining the directory to store the generator check points\n",
    "    g_checkpoint_path = os.path.join(FLAGS.logdir, 'gckpt/')\n",
    "    print('G checkpoint path: ', g_checkpoint_path)\n",
    "    ##Defining the directory to store the discriminator check points\n",
    "    d_checkpoint_path = os.path.join(FLAGS.logdir, 'dckpt/')\n",
    "    print('D Checkpoint Path:',d_checkpoint_path)\n",
    "\n",
    "    if not os.path.exists(g_checkpoint_path):\n",
    "        os.makedirs(g_checkpoint_path)\n",
    "\n",
    "    if not os.path.exists(d_checkpoint_path):\n",
    "        os.makedirs(d_checkpoint_path)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.logdir, graph=sess.graph)\n",
    "        newStepNo = 0\n",
    "        # restore or initialize generator\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        gckpt = tf.train.get_checkpoint_state(g_checkpoint_path)\n",
    "        if gckpt and gckpt.model_checkpoint_path:\n",
    "            g_saver.restore(sess, gckpt.model_checkpoint_path)\n",
    "            print('Model restored from ' + gckpt.model_checkpoint_path)\n",
    "            newStepCheck = gckpt.model_checkpoint_path\n",
    "            newStepNo = int(newStepCheck.split('-')[1])\n",
    "        #if os.path.exists(g_checkpoint_path):\n",
    "            #print('restore variables for G:')\n",
    "            #for v in dcgan.g.variables:\n",
    "                #print('  ' + v.name)\n",
    "            #g_saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            #g_saver.restore(sess, g_checkpoint_path)\n",
    "        #if os.path.exists(d_checkpoint_path):\n",
    "            #print('restore variables for D:')\n",
    "            #for v in dcgan.d.variables:\n",
    "              #  print('  ' + v.name)\n",
    "            #d_saver.restore(sess, d_checkpoint_path)\n",
    "\n",
    "        dckpt = tf.train.get_checkpoint_state(d_checkpoint_path)\n",
    "        if dckpt and dckpt.model_checkpoint_path:\n",
    "            d_saver.restore(sess, dckpt.model_checkpoint_path)\n",
    "            print('Model restored from ' + dckpt.model_checkpoint_path)\n",
    "\n",
    "        # setup for monitoring\n",
    "        sample_z = sess.run(tf.random_uniform([dcgan.batch_size, dcgan.z_dim], minval=-1.0, maxval=1.0))\n",
    "        images = dcgan.sample_images(1, 1, inputs=sample_z)\n",
    "\n",
    "        # start training\n",
    "        tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "        #for step in range(FLAGS.max_steps):\n",
    "        while newStepNo <= FLAGS.max_steps:\n",
    "            start_time = time.time()\n",
    "            _, g_loss, d_loss = sess.run([train_op, losses[dcgan.g], losses[dcgan.d]])\n",
    "            duration = time.time() - start_time\n",
    "            print('{}: step {:5d}, loss = (G: {:.8f}, D: {:.8f}) ({:.3f} sec/batch)'.format(\n",
    "                datetime.now(), newStepNo, g_loss, d_loss, duration))\n",
    "\n",
    "            # save generated images\n",
    "            if newStepNo % 100 == 0:\n",
    "                # summary\n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str, newStepNo)\n",
    "                # sample images\n",
    "                filename = os.path.join(\"C:\\\\Users\\\\sedkilic\\\\immages\", '%05d.png' % newStepNo)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(sess.run(images))\n",
    "            # save variables\n",
    "            if newStepNo % 500 == 0:\n",
    "                g_saver.save(sess, g_checkpoint_path + 'g.ckpt', global_step=newStepNo)\n",
    "                print('Save mode for G in checkpoint_path: ', g_checkpoint_path)\n",
    "                d_saver.save(sess, d_checkpoint_path + 'd.ckpt', global_step=newStepNo)\n",
    "                print('Save mode for D in checkpoint_path: ', d_checkpoint_path)\n",
    "                #g_saver.save(sess, g_checkpoint_path, global_step=step)\n",
    "                #d_saver.save(sess, d_checkpoint_path, global_step=step)\n",
    "            newStepNo = newStepNo+1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
